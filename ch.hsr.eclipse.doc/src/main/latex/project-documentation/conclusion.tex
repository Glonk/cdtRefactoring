\chapter{Conclusions, Interpretation and Future Work}
\thispagestyle{fancy}

During the project, a lot of challenges have been discovered which will be 
documented in the following sections along with a look back on the whole project 
and an outlook on what could be done in further theses. 

\section{Conclusions}

\subsection{\textit{Toggle Function Definition}}
The main goal of the project was to create a stable refactoring that would have 
a chance to be integrated into CDT. In the view of the authors, the developed 
plug-in became quite handy but should be tested by a larger community before it 
may be released to the public. One of the drawback is the issue with
whitespaces which are not handled satisfactorily. See section \ref{newlines}
about newlines.

Anyhow, it should be taken into account that the C++ language specification (and 
its implementations by different compilers) may offer a lot more features 
than two developers could ever think of. It is not sure whether the covered
special cases are enough general to cover all language constructs that may
exist. Even programming against the C++ language specification is no guarantee
that the refactoring will behave correctly out in the wild.

All in all, the developer team is proud of the solution although aware of the 
fact that there may still be some improvements needed to satisfy a large 
audience.

\subsection{Implement Function}
\textit{Implement Function} shares a lot of similarities and benefits of
functionality developed for the \textit{Toggle Function Definition}. This
refactoring was developed in short time after the \textit{Toggle Function
Definition}.

\subsection{Override Virtual Function}
No deeper investigation on how this refactoring could benefit from the developed 
work has been done until now. This is still left to be implemented as another
semester or bachelor thesis.

\section{Known issues}

\subsection{Constructor / Destructor Bug}
\textbf{Problem}: Let CDT create a new class with a constructor and a destructor. 
Then toggle the constructor out of the class definition. The Destructor will be 
overridden partially. This bug can also be triggered when a function above a
constructor or a destructor is toggled. It seems that it is triggered with
function names which do not have a type information and the \texttt{replace()}
method of the ASTRewrite.
There are some ways to prevent this bug, although it is not really a workaround.
First the destructor can be made virtual. In the function above, arguments will
also prevent this bug.

\textbf{Cause}: Unknown. It seems to be an offset bug and/or a rewriter bug.

\textbf{Solution}: Not yet solved.

\label{newlines}
\subsection{Unneccessary Newlines}
\textbf{Problem}: When toggling multiple times, a lot of newlines are generated 
by the rewriter. 

\textbf{Cause}: Newlines are inserted by the rewriter before and after an new
node but are not removed when removing the same node. To be able to judge how 
many newlines have to be inserted or removed, the whitespace situation around an 
affected node has to be analyzed thoroughly. Given figure \ref{commentA} it 
could be tried to always remove one newline before and one newline after the 
removed function.

\begin{lstlisting}[caption={Whitespaces will not be removed blindly},
label={commentA}, language=C++]
void before() {
}
// 1st newline added
void newFunction() {
} // 2nd newline added

void after() {
}
\end{lstlisting}

Yet, it is not determined whether the programmer changed the code to look like 
in figure \ref{commentB}. There, it would be fatal to remove a character before 
and after the function because brackets would be removed instead.

\begin{lstlisting}[caption={Code without the usual newlines},
label={commentB}, language=C++]
void before(){}void newFunction(){}void after(){}
\end{lstlisting}

\textbf{Workaround}: First, the formatter could be used to remove multiple 
newlines. This breaks the programmers formatting which could be disruptive. 
Another solution is to manually change the generated text edits to avoid 
inserting or to delete more newlines. However, the changes are highly coupled to 
the different refactoring strategies. When this solution was tried to be 
implemented, it was a problem too that the generated text edits were changing 
their array positions, which made changes even more difficult. The resulting 
code was unstable and this solution is not recommended. 

\subsection{Comment Handling}
\textbf{Problem}: A lot of freestanding comments are generated when
toggling multiple times. These comments become leading if a function gets
toggled below these freestanding comments.

\textbf{Cause}: When a node is removed by the rewriter, associated comments are 
not removed. This may be seen as a defensive strategy to avoid deleting comments 
accidentally. The ASTRewrite adopts all comments above a node as a leading
comment not caring how many spaces or lines there are between node and comment.

\textbf{Solution}: No solution yet. This could be solved by a new rewriter.

\subsection{Menu Integration (partially solved)}
\textbf{Problem}: Adding a new menu item to the refactor menu is difficult when 
developing a separate plug-in.

\textbf{Cause}: Menu items are hardcoded inside
\textit{CRefactoringActionGroup}. No way was found to replace or change this 
class within a separate plug-in. In addition, the use of the 
\textit{org.eclipse.ui.actionSets} extension point does not make inserting new 
items easier.

\textbf{Workaround}: The menu was added using \textit{plug-in.xml} and may be added 
by the user manually. See the manual in \ref{cmdGroup} to solve this issue. 
Anyhow, the refactoring may always be invoked using the key binding. 

\subsection{Preprocessor Statements}
\label{preprocessor}
\textbf{Problem}: If a preprocessor statement (e.g. \textit{\#ifdef}) is
contained inside the parent of a rewritten, removed or inserted node, the
preprocessor statement is deleted. Listing \ref{prepro} shows an example where a
class is rewritten and a contained preprocessor statement is removed as a side
effect.

\begin{lstlisting}[caption={Jeopardized preprocessor statement inside a class},
label={prepro}, language=C++]
#ifdef EXAMPLE_H_           // not affected
#define EXAMPLE_H_          // not affected

class WillBeRewrittenImplicitly {
  #ifdef _X86__             // will be removed
    void specificCode() {}  // will be removed
  #endif                    // will be removed

  void toBeManipulatedFunction(); // rewrite this
};

#endif                      // not affected
\end{lstlisting}

\textbf{Cause}: The rewriter does not support preprocessor statements.

\textbf{Solution}: None yet. This has to be solved by a fix for the rewriter
which supports preprocessor statements.

There was a small work around for this problem by warning about the presence of
a preprocessor statement in the affected files. In the end this was dropped
because this breaks the initial idea of the code flow.

\subsection{Doxygen}

\textbf{Problem}: The whitespace issue was already discussed. Another issue is
that the Doxygen \cite{Doxygen} syntax \texttt{//!} may not be used in the test
files since this syntax is used to specify the test name.

\textbf{Cause}: Refactoring tests need the \texttt{//!} syntax to specify the
refactoring class which should be called for the selected code.

\textbf{Solution}: It was not looked for a solution to this problem. A solution
to this problem could be to change the syntax for controlling the refactoring
tests to something else.

\subsection{Resource '/RegressionTestProject/A.h' does not Exist.}

\textbf{Problem}: When running refactoring test cases, a message randomly
popped up:

\begin{lstlisting}[caption={Randomly appearing error message},language=java]
!ENTRY org.eclipse.cdt.core 4 0 2010-12-13 ...
!MESSAGE Error: Resource '/RegressionTestProject/\
A.h' does not exist.
!STACK 1
org.eclipse.core.internal.resources.\
ResourceException: Resource '/RegressionTest\
Project/A.h' does not exist.
  at...ces.Resource.checkExists(Resource.java:326)
  [...]
\end{lstlisting}

\textbf{Cause}: Unknown (no deeper investigation)

\textbf{Solution}: Tests still pass without failure. It seemed this is no root
of a problem. However it should be mentioned here.

\section{Solved Issues}

This section describes special cases that have been omitted intentionally or due 
to lack of time. In addition, found limitations of the CDT are described here.

\subsection{Speed}
\textbf{Problem}: Refactoring, especially the first run, was very slow in the 
beginning. Including a big header file slowed down the process even more.

\textbf{Cause}: The first thought was that header file indexing was the cause. 
However, the indexer option that skips already indexed headers is enabled in 
\textit{CRefactoring}. In the end, it was found out that most of the time was 
consumed by the \textit{checkInitialConditions} method of \textit{CRefactoring} 
that checked for problems inside the translation unit.

\textbf{Solution}: The super call to \textit{checkInitialConditions} was
omitted. Additionally separated and isolated translation units were created and
indexed with options to prevent reindexing of already indexed files.
%TODO: add some code here how to do this

\subsection{Accessing Standalone Header Files}
\textbf{Problem}: Header files that are not included in any source file by 
default were not found by the indexer. Thus, it was not possible to analyze the 
source code of the affected header file.

\textbf{Cause}: By default, the indexer preference option 
\textit{IndexerPreferences.KEY\_INDEX\_UNUSED\_HEADERS\_WITH\_DEFAULT\_LANG} is 
set to false. However, this option is needed for standalone header files to be 
indexed.

\textbf{Solution}: Set the described option in \textit{IndexerPreferences} to 
true.

\subsection{Indexing all Projects}

\textbf{Problem}: Having multiple projects with the same file containing the
same functions causes the plug-in to crash. 

\textbf{Cause}: In the index provided by the \texttt{CRefactoring} class
returns an index containing all the indexes over all the open projects. This
option makes only sense for refactorings like an ``organize include statements''

\textbf{Solution}: Providing our own project local index and omit functionality
from CRefactoring class.

\subsection{Selection}
\textbf{Problem}: After toggling multiple times, the wrong functions were 
toggled or no selected function was found at all. 

\textbf{Cause}: The region provided by \textit{CRefactoring} pointed to a wrong 
code offset. This happens due to the fact that 
\textit{IWorkbenchWindowActionDelegate}'s \textit{selectionChanged} method is 
updated with outdated offset information.

\textbf{Solution}: The current selection is now based directly on the current 
active editor part's selection and fetched every time when toggling is started.

\subsection{Fuzzy Whitespace Recognition Test Environment}

\textbf{Problem}: 
In past theses at HSR, the refactoring testing environment needed an exact
definition of the generated code. This was annoying because same-looking code
samples could result in a red bar if white spaces were not the same. To make
writing new tests easier, the comparison method was overridden to support fuzzy
whitespace recognition.

\textbf{Cause}: The \texttt{TesterHelper} in the CDT test environment does
compare the whole actual and expected code as \texttt{String} with \cite{JUnit}
\texttt{AssertEquals(String, String)}. This leads to the a failing test as
soon as a single whitespace is different between the expected and the actual
code.

\textbf{Solution}: Leading whitespaces are recognized on both. Then the smallest
common divider is taken as as a tab length and replaced by a tabulator. Trailing
superfluous newlines that are added by the ASTRewriter are ignored and also
trailing whitespaces at the end of a line. After that the edited code goes to
the \texttt{assert()} for comparison.

\subsection{Comments and Macros}
\textbf{Problem}: Nodes inside a translation unit have to be copied to be 
changed since they are frozen. When nodes are copied, their surrounding comments 
get lost during rewrite\cite{Sommerlad:2008:RCR:1449814.1449817}. This was
annoying, since copying the function body provided a straightforward solution
for replacing a declaration with a definition.

Another issue were macros. Macros are working perfectly when copied and 
rewritten inside the same translation unit. As soon as a macro is moved outside 
a translation unit, the macro will be expanded during rewrite or even
deleted when no information about the macro is found.

\textbf{Cause}: The rewriter is using a method in \texttt{ASTCommenter} to get a 
\texttt{NodeCommentMap} of the rewritten translation unit. If a node is copied, 
it has another reference which won't be inside the comment map anymore. Thus, 
when the rewriter writes the new node, it won't notice that the node was 
replaced by another.

\textbf{Solutions}:
\begin{itemize}
\item Get the raw signature of the code parts that should be copied and insert 
them using an ASTLiteralNode. 

Pro: It works without changing the CDT core and macros are not expanded. 

Contra: Breaks indentation and inserts unneeded newlines. This solution was used 
finally because whitespace issues may be dealt with the formatter.
\item Do as \texttt{ExtractFunction} does: rewrite each statement inside the 
function body separately. 

Pro: automatic indentation. 

Contra: touches the body although it does not need to be changed in any way. 
\item Change the CDT: Inside the \texttt{ChangeGenerator.generateChange}, the 
\texttt{NodeCommentMap} of the translation unit is fetched. By writing a patch, 
it was possible to insert new mappings into this map. This allowed to move 
comments of an old node to any newly created node. 

Pro: automatic indentation, developer may choose where to put the comments, 
every comment may be preserved. 

Contra: does not deal with macros, five classes need to be changed in CDT, 
comments need to be moved by hand. See the branch 'inject' inside the repository 
to study this solution.
\item Find and insert comments by hand using an IASTComment. 

Pro: lets the developer decide where to put the comment. 

Contra: Feature is commented-out in the 7.0.1 release of CDT, comments need to 
be moved by hand.
\item Other solutions may be possible. An idea could be to register the comments 
whenever a node is being copied. Since \textit{copy} is abstract in 
\textit{IASTNode} and implemented separately inside every node, this would 
require a change inside every node class.
\end{itemize}

\subsection{Toggling Function-Local Functions}
\textbf{Problem}: When using function-local functions, the refactoring may 
produce code that won't compile.

\textbf{Cause}: Despite in the C++ standard\cite{IsoCpp} function-local 
functions are not allowed, the Gnu C Compiler allows to define such nested 
functions\cite{GCC}. In this case the selection detection finds the nested 
function if selected and it is tried to toggle it. However, it is not guaranteed 
that valid code will be generated.

\textbf{Solution}: Toggling is disabled for such nested function definitions.

\section{Further Work}

The toggle refactoring was developed as a separate plug-in so integration into 
the CDT project should be possible if desired.

It should be a small task to provide a solution for multi-toggling. If the user 
selects more than one definition, all of them could be toggled. An example 
workflow could be "Create new class (inherit from an abstract class)", "add 
unimplemented methods", "toggle all methods to an implementation file".

A big problem in this refactoring was the rewriter. Since it is limited in its
functionality by limited support for comments, no preprocessor statement
support, inserting newlines over and over, and even producing wrong code with
the constructor bug (see section \ref{Constructor / Destructor bug}), it is
extremely time consuming to find workarounds for such problems.
Therefore before any new refactoring is developed, the rewriter should be
fixed or rewritten.
As in the last meeting of this semester thesis with the supervisor, it was
ensured such a work will be done by the Institut fuer Software.

A mechanism could be implemented that fixes indentation after refactoring.
Better user feedback in case of errors could be provided.

At the end there was no time left to do the \textit{Override virtual member
function} refactoring. This is still left as a semester thesis.

\section{Interpretation}
\thispagestyle{fancy}

After implementation, a personal look back was made on what the resulting
refactoring is capable of and what may still need some improvement.

\subsection{Features and Limitations}

Toggling functions is available inside any class or namespace hierarchy and may 
be invoked when the selection is anywhere inside a function declaration or
body. 
Basic templated functions are supported as well. However, there may be 
template special cases that were not thought of.

On the other side, the code generator removes preprocessor statements that stay 
inside a node that has to be rewritten. Removing comments of removed nodes was 
not achieved without changing the rewriter.

\subsection{Performance Results}

It is difficult to compare the speed with other refactorings of CDT since
wizards are used for the other known refactorings. However, the goal was reached
that the refactoring is executing almost instantly.

It was planned to measure the speed of the JUnit tests. However, the displayed 
time does not represent the actual speed of the refactoring. This may be due to 
the fact that/ tests are not being invoked exactly the same way as the actual 
refactoring./ The manually invoked refactoring is run with the help of
\texttt{ToggleRefactoringRun- ner}.

The results from the \textit{org.eclipse.test.performance} speed tests were not 
used either. Since in reality the refactorings are much slower than the 
(repeated) measurements, resulting values may only be compared relative to each 
other.

In the end, the only way to judge whether the refactorings became quicker is to 
check out an older version and to try it out manually. Included libraries like
iostream slowed down the refactoring noticeably before speed was improved.

\subsection{Personal Review}

Some words from the authors about the developed plug-in, project management, of 
what was fun and what not.

\subsubsection{Martin Schwab}

What I like about the developed refactoring is that it was possible to
implement 
it without a wizard. However, the user needs full trust in the code generation 
that it won't break code and this is currently not given when preprocessor 
statements are used. Nevertheless I'm glad the developed plug-in is able to
write 
complex template definitions that I couldn't write myself without the C++ 
specification by my side. This could save a lot of time and hassle for 
programmers.

What next? If the plug-in is integrated into CDT, I'd be interested in the 
Eclipse Usage Data Collector
\footnote{\url{http://www.eclipse.org/org/usagedata/results.php}} to check 
whether users find out when and how they can profit from the refactoring and 
whether they use it repeatedly. If the refactoring is considered helpful by 
users and applied as it is designed to use, this should be reflected in a high 
execution count compared to the user count.

\subsubsection{Thomas Kallenberg}

Personally I like the C++ programming language. Despite the complexity it can
be an alternative to Java or other OOP languages. Specially if there is a focus
on performance or other subjects where templates do fit nicely in the concept
of the project.
The one touch toggle refactoring is another step towards a better knowledge of
C++.

What I liked about the project was the clear and productive communication with
the supervisor. The Environment to develop a CDT Refactoring provided enough
functionality to develop a good refactoring in the given time scope but let us
enough freedom to realize innovative ideas.

The goal was to develop a plug-in that is used by the world and not thrown away.
Even if we could not solve all issues, specially with comments and macros, I
think we achieved the main task and realized our supervisors and customers 
idea of a toggle definition.

\subsubsection{What we would do the same way}

Using Git\footnote{\url{http://www.kernel.org/pub/software/scm/git/}} for
version 
control was very useful. The provided development server was occasionally down 
during the first weeks and it was possible to continue work locally. Being able 
to work locally was also helpful to work on the train. 

Working next to each other in the same study room was helpful to get quick 
answers for questions, reduce slow written communication and playing a round of 
table foot when concentration was used up.

For each meeting, the planned tasks were collected inside the agenda, then 
rubber-stamped by the supervisor and transformed into issues for the following 
week. This way, a minimal administrative overhead was produced.

\subsubsection{What we would not do the same way}

\subsubsection*{Time management}
During most of the project, time was tracked for every issue. 
However, the collected data was not actively used to measure team velocity and 
estimate further issues. This valuable data could have been used for better 
scope prediction.

\subsubsection*{Commits not Connected with Issues}

During the project we ``forgot'' sometimes to trak our time. Sometimes it was
really simply forgotten and sometimes it was delayed (and then forgotten) to
speed up implementation of the functionality. This is clearly not a good thing
since the danger is high to forget about the tracked time as it happend to us
many times.

As an improvements in the bachelor thesis we thought about connecting every
commit to the version control with an issue. It could even be checked with a
server side script during commiting. If the commit message does not contain a
valid issue number the commit is rejected. This forces the developer to connect
his commit to an issue.

\subsubsection*{Wiki and Documentation differences}

The special cases that were listed on the project wiki were useful to 
communicate but it may have saved time if they were directly integrated into 
the documentation.

\subsubsection*{Writing Documentation at the End}

We knew about the fact that writing documentation at the end is a hard thing
due to time shortage. We created the documentation structure early and started
to write some text to it. But somewhere in the middle of the project we did not
kept in mind to continue this. This and changes to the code until the end led
to a lot of stress in the last two weeks since the documentation was not
written so far as expected.

Chapters like specification should be written early. The wiki is not read, but
the documentation is read and if written early mistakes do not life long, as
long as the documentation is read several times.

Glossary should be written continuously and even some parts of the
implementation needs to be documented early.

\subsubsection*{Redmine fine tuning}

The default Redmine \textit{trackers} and \textit{categories} that were used 
were not sufficient to track time in a way that shiny charts could be produced 
for categories like ''implementation'', ''documentation'' and ''administration. 

\subsubsection*{Multiple git branches}

While using one master git branch for every developer, a second git branch 
called development was introduced. During half a week new work was committed to
the
development branch and then both trees were merged. The idea behind this was to
always have a stable master branch. This allowed to carelessly mess around
inside the development branch which resulted in nobody daring
to pull from the others branch. Inside the master branch everything was already
merged and
the development branch was in an ``always unstable'' condition.
If something unstable is introduced to the repository one should explicitly use
a separate branch and include this in the master as soon as possible.